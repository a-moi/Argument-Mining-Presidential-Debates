{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-superior",
   "metadata": {},
   "source": [
    "<h2>Load the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "missing-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "auburn-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = []\n",
    "for name in glob.glob('ElecDeb60To16/*.txt'):\n",
    "    name = name.replace('\\\\','/')\n",
    "    txt_files.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "derived-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElecDeb60To16/01_1960.txt\n",
      "ElecDeb60To16/02_1960.txt\n",
      "ElecDeb60To16/03_1960.txt\n",
      "ElecDeb60To16/04_1960.txt\n",
      "ElecDeb60To16/05_1976.txt\n",
      "ElecDeb60To16/06_1976.txt\n",
      "ElecDeb60To16/07_1976.txt\n",
      "ElecDeb60To16/08_1980.txt\n",
      "ElecDeb60To16/09_1980.txt\n",
      "ElecDeb60To16/10_1984.txt\n",
      "ElecDeb60To16/11_1984.txt\n",
      "ElecDeb60To16/12_1984.txt\n",
      "ElecDeb60To16/13_1988.txt\n",
      "ElecDeb60To16/14_1988.txt\n",
      "ElecDeb60To16/15_1988.txt\n",
      "ElecDeb60To16/16_1992.txt\n",
      "ElecDeb60To16/17_1992.txt\n",
      "ElecDeb60To16/18_1992.txt\n",
      "ElecDeb60To16/19_1992.txt\n",
      "ElecDeb60To16/20_1992.txt\n",
      "ElecDeb60To16/21_1992.txt\n",
      "ElecDeb60To16/22_1996.txt\n",
      "ElecDeb60To16/23_1996.txt\n",
      "ElecDeb60To16/24_1996.txt\n",
      "ElecDeb60To16/25_2000.txt\n",
      "ElecDeb60To16/26_2000.txt\n",
      "ElecDeb60To16/27_2000.txt\n",
      "ElecDeb60To16/28_2000.txt\n",
      "ElecDeb60To16/29_2004.txt\n",
      "ElecDeb60To16/30_2004.txt\n",
      "ElecDeb60To16/31_2004.txt\n",
      "ElecDeb60To16/32_2004.txt\n",
      "ElecDeb60To16/33_2008.txt\n",
      "ElecDeb60To16/34_2008.txt\n",
      "ElecDeb60To16/35_2008.txt\n",
      "ElecDeb60To16/36_2008.txt\n",
      "ElecDeb60To16/37_2012.txt\n",
      "ElecDeb60To16/38_2012.txt\n",
      "ElecDeb60To16/39_2012.txt\n",
      "ElecDeb60To16/40_2012.txt\n",
      "ElecDeb60To16/41_2016.txt\n",
      "ElecDeb60To16/42_2016.txt\n"
     ]
    }
   ],
   "source": [
    "speech_list = []\n",
    "\n",
    "for file in txt_files:\n",
    "    sent_list = []\n",
    "    print(file)\n",
    "    \n",
    "    with open(file) as infile:\n",
    "        for line in infile:\n",
    "            line = re.sub(r'[A-Z]*: ','',line)\n",
    "            line = re.sub(r'\\[[a-zA-Z0-9;,\\s\\\"\\:\\'\\.\\S]*\\]*','',line)\n",
    "\n",
    "            for sent in tokenize.sent_tokenize(line):\n",
    "                sent_list.append(sent)\n",
    "    \n",
    "    speech_list.append(sent_list)\n",
    "\n",
    "\"Up to this point we get a speech_list containing every speech (42 total) tokenized into sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-growing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
