{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "portuguese-shepherd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from nltk import tokenize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Bidirectional, Embedding, Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "american-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'updated_csv.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df2 = df[df.Annotation != 'None']\n",
    "\n",
    "#task 1, compile all sentences(for feature engineering) and corresponding labels, 1 for containing argument component\n",
    "all_sentences = df.iloc[:, 1].tolist()\n",
    "all_labels = df.iloc[:, 2].tolist()\n",
    "for i in range(len(all_labels)):\n",
    "    if all_labels[i] == \"Claim\" or all_labels[i] == \"Premise\":\n",
    "        all_labels[i] = 1\n",
    "    else:\n",
    "        all_labels[i] = 0\n",
    "        \n",
    "#task 2, compile only sentences containing claim/premise(for feature engineering) and corresponding labels, 1 for claim\n",
    "cp_sentences = df2.iloc[:, 1].tolist()\n",
    "cp_labels = df2.iloc[:, 2].tolist()\n",
    "for i in range(len(cp_labels)):\n",
    "    if cp_labels[i] == \"Claim\":\n",
    "        cp_labels[i] = 1\n",
    "    else:\n",
    "        cp_labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "several-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "FT = \"fasttext/wiki-news-300d-1M.vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "foreign-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = KeyedVectors.load_word2vec_format(FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empty-tribune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('economies', 0.7268105149269104),\n",
       " ('Economy', 0.6976400017738342),\n",
       " ('ecomony', 0.6842233538627625),\n",
       " ('ecomomy', 0.6667296886444092),\n",
       " ('economics', 0.6634849905967712),\n",
       " ('economic', 0.6561825275421143),\n",
       " ('society', 0.6531913876533508),\n",
       " ('econmy', 0.6524451375007629),\n",
       " ('recession', 0.6477683186531067),\n",
       " ('econony', 0.6444004774093628)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities = fasttext.most_similar(positive=['economy'])\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "refined-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest word:  28\n",
      "longest sentence:  ['Now', ',', 'when', 'we', 'have', 'a', 'presidential', 'candidate', ',', 'for', 'example', '-', 'Senator', 'Kennedy', '-', 'stating', 'over', 'and', 'over', 'again', 'that', 'the', 'United', 'States', 'is', 'second', 'in', 'space', 'and', 'the', 'fact', 'of', 'the', 'matter', 'is', 'that', 'the', 'space', 'score', 'today', 'is', 'twenty-eight', 'to', 'eight', '-', 'we', \"'ve\", 'had', 'twenty-eight', 'successful', 'shots', ',', 'they', \"'ve\", 'had', 'eight', ';', 'when', 'he', 'states', 'that', 'we', \"'re\", 'second', 'in', 'education', ',', 'and', 'I', 'have', 'seen', 'Soviet', 'education', 'and', 'I', \"'ve\", 'seen', 'ours', ',', 'and', 'we', \"'re\", 'not', ';', 'that', 'we', \"'re\", 'second', 'in', 'science', 'because', 'they', 'may', 'be', 'ahead', 'in', 'one', 'area', 'or', 'another', ',', 'when', 'overall', 'we', \"'re\", 'way', 'ahead', 'of', 'the', 'Soviet', 'Union', 'and', 'all', 'other', 'countries', 'in', 'science', ';', 'when', 'he', 'says', 'as', 'he', 'did', 'in', 'January', 'of', 'this', 'year', 'that', 'we', 'have', 'the', 'worst', 'slums', ',', 'that', 'we', 'have', 'the', 'most', 'crowded', 'schools', ';', 'when', 'he', 'says', 'that', 'seventeen', 'million', 'people', 'go', 'to', 'bed', 'hungry', 'every', 'night', ';', 'when', 'he', 'makes', 'statements', 'like', 'this', ',', 'what', 'does', 'this', 'do', 'to', 'American', 'prestige', '?']\n",
      "longest sentence length:  173\n"
     ]
    }
   ],
   "source": [
    "all_sent_tokenized = []\n",
    "longest_word_len = []\n",
    "for i in range (len(all_sentences)):\n",
    "    all_sent_tokenized.append(word_tokenize(all_sentences[i]))\n",
    "    longest_word_len.append(len(max(all_sent_tokenized[i], key=len)))\n",
    "\n",
    "print(\"longest word: \", max(longest_word_len))    \n",
    "print(\"longest sentence: \", max(all_sent_tokenized,key=len))\n",
    "print(\"longest sentence length: \", len(max(all_sent_tokenized,key=len)))\n",
    "\n",
    "max_seq_len = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "motivated-surname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (36201, 180)\n"
     ]
    }
   ],
   "source": [
    "unique_words = len(fasttext)\n",
    "\n",
    "word_index = {t[0]: i+1 for i,t in enumerate(Counter().most_common(unique_words))}\n",
    "sequences = [[word_index.get(t, 0) for t in sent] for sent in all_sentences]\n",
    "\n",
    "# pad\n",
    "data = pad_sequences(sequences, maxlen=max_seq_len, padding=\"pre\", truncating=\"post\")\n",
    "\n",
    "print('Shape of data:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "protected-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we initialize the matrix with random numbers\n",
    "embedding_matrix = (np.random.rand(unique_words, 300) - 0.5) / 5.0\n",
    "for word, i in word_index.items():\n",
    "    if i >= unique_words:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = fasttext[word]\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acquired-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_cat = to_categorical(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "optical-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_true = train_test_split(data, all_labels_cat, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alive-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999994\n"
     ]
    }
   ],
   "source": [
    "unique_words = len(fasttext)\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "greater-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Index                                          Sentences Annotation\n",
      "0          7                                      Good evening.       None\n",
      "1         21  The television and radio stations of the Unite...       None\n",
      "2        247               The candidates need no introduction.       None\n",
      "3        284  The Republican candidate, Vice President Richa...       None\n",
      "4        398  According to rules set by the candidates thems...       None\n",
      "...      ...                                                ...        ...\n",
      "36196  46019                                    Thank you both.       None\n",
      "36197  46035  While millions have already voted, Election Da...       None\n",
      "36198  46120  One thing everyone here can agree on: We hope ...       None\n",
      "36199  46184  It is one of the honors and obligations of liv...       None\n",
      "36200  46257                         Thank you, and good night.       None\n",
      "\n",
      "[36201 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "broke-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, None, 300)         299998200 \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 300,319,402\n",
      "Trainable params: 321,202\n",
      "Non-trainable params: 299,998,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('cpu:0'):\n",
    "  embedding_layer = Embedding(len(fasttext), 300, weights = [embedding_matrix] , trainable=False)\n",
    "  embedding_layer.build((len(fasttext), 300))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=False), input_shape=(300, 1)))\n",
    "model.add(Dense(2,activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "usual-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27150/27150 [==============================] - 217s 8ms/step - loss: 0.6573 - accuracy: 0.6348\n",
      "Epoch 2/10\n",
      "27150/27150 [==============================] - 221s 8ms/step - loss: 0.6565 - accuracy: 0.6355\n",
      "Epoch 3/10\n",
      "27150/27150 [==============================] - 217s 8ms/step - loss: 0.6563 - accuracy: 0.6355\n",
      "Epoch 4/10\n",
      "27150/27150 [==============================] - 218s 8ms/step - loss: 0.6566 - accuracy: 0.6355\n",
      "Epoch 5/10\n",
      "27150/27150 [==============================] - 218s 8ms/step - loss: 0.6563 - accuracy: 0.6355\n",
      "Epoch 6/10\n",
      "27150/27150 [==============================] - 218s 8ms/step - loss: 0.6564 - accuracy: 0.6355\n",
      "Epoch 7/10\n",
      "27150/27150 [==============================] - 217s 8ms/step - loss: 0.6562 - accuracy: 0.6355\n",
      "Epoch 8/10\n",
      "27150/27150 [==============================] - 217s 8ms/step - loss: 0.6560 - accuracy: 0.6355\n",
      "Epoch 9/10\n",
      "27150/27150 [==============================] - 222s 8ms/step - loss: 0.6562 - accuracy: 0.6355\n",
      "Epoch 10/10\n",
      "27150/27150 [==============================] - 219s 8ms/step - loss: 0.6562 - accuracy: 0.6355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e7103da808>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-drama",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
